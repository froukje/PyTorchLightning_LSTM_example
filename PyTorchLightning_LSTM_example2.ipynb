{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "* Predict power usage of a day (\"Value (kWh)\")\n",
    "* Use dataset from https://www.kaggle.com/srinuti/residential-power-usage-3years-data-timeseries\n",
    "* The data has been prepared in the \"DataPreparation.ipynb\" notebook\n",
    "* Again, the purpose of this exercise is more to get more familiar with PyTorchLightning and LSTMs than getting the perfect prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers.csv_logs import CSVLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PowUseDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y, seq_len):\n",
    "        self.X = torch.tensor(X).float()\n",
    "        self.y = torch.tensor(y).float()\n",
    "        self.seq_len = seq_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.__len__() - (self.seq_len - 1)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.X[idx:idx+self.seq_len-1], self.y[idx+self.seq_len-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PowUsageDataModule(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(self, seq_len, batch_size, num_workers):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        \n",
    "    def setup(self, stage):\n",
    "        \n",
    "        # read data\n",
    "        df_total = pd.read_csv('data/df_total.csv')\n",
    "        \n",
    "        # define  X and y\n",
    "        columns = ['Temp_max','Temp_avg','Temp_min','Dew_max','Dew_avg','Dew_min','Hum_max','Hum_avg','Hum_min','Wind_max','Wind_avg','Wind_min','Press_max','Press_avg','Press_min','Precipit','day_of_week_pow']\n",
    "        \n",
    "        X  = df_total[columns].values\n",
    "        \n",
    "        y = df_total['Value (kWh)'].values\n",
    "        \n",
    "        # split data\n",
    "        self.X_test, X_tmp, self.y_test, y_tmp = train_test_split(X, y, test_size=.2)\n",
    "        self.X_val, self.X_train, self.y_val, self.y_train = train_test_split(X_tmp, y_tmp, test_size=.25)\n",
    "        \n",
    "        # reshape labels\n",
    "        self.y_train = self.y_train.reshape(-1,1)\n",
    "        self.y_val = self.y_val.reshape(-1,1)\n",
    "        self.y_test = self.y_test.reshape(-1,1)\n",
    "        \n",
    "        # normalize data\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(self.X_train)\n",
    "        scaler.transform(self.X_train)\n",
    "        scaler.transform(self.X_val)\n",
    "        scaler.transform(self.X_test)\n",
    "        \n",
    "        minmax = MinMaxScaler()\n",
    "        minmax.fit(self.y_train)\n",
    "        minmax.transform(self.y_train)\n",
    "        minmax.transform(self.y_val)\n",
    "        minmax.transform(self.y_test)\n",
    "        \n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        \n",
    "        # create dataset\n",
    "        train_dataset = PowUseDataset(self.X_train, self.y_train, seq_len=self.seq_len)\n",
    "        \n",
    "        # wrap in dataloader\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=False, \n",
    "                                      num_workers=self.num_workers)\n",
    "        return train_dataloader\n",
    "        \n",
    "    def val_dataloader(self):\n",
    "        \n",
    "        # create dataset\n",
    "        val_dataset = PowUseDataset(self.X_val, self.y_val, seq_len=self.seq_len)\n",
    "        \n",
    "        # wrap in dataloader \n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False,\n",
    "                                   num_workers=self.num_workers)\n",
    "        return val_dataloader\n",
    "        \n",
    "    def test_dataloader(self):\n",
    "        \n",
    "        # create dataset\n",
    "        test_dataset = PowUseDataset(self.X_test, self.y_test, seq_len=self.seq_len)\n",
    "        \n",
    "        # wrap in dataloader \n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False,\n",
    "                                   num_workers=self.num_workers)\n",
    "        return test_dataloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PowUsageModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, input_size, learning_rate,\n",
    "                hidden_size, num_layers, dropout, \n",
    "                criterion):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.train_losses = []\n",
    "        self.train_losses_epoch = []\n",
    "        self.val_losses = []\n",
    "        self.val_losses_epoch = []\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.learning_rate = learning_rate\n",
    "        self.criterion = criterion\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=self.input_size,\n",
    "                            hidden_size=self.hidden_size,\n",
    "                            num_layers=self.num_layers,\n",
    "                            dropout=self.dropout,\n",
    "                            batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x, _ = self.lstm(x) # x=(batch_size, seq_len, hidden_size)\n",
    "        x = self.fc(x[:,-1])\n",
    "         \n",
    "        return x\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.train_losses.append(loss.item())\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        log = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': log}\n",
    "        #return loss\n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.val_losses.append(loss.item())\n",
    "        self.log('val_loss', loss)\n",
    "        log = {'val_loss': loss}\n",
    "        return {'val_loss': loss, 'log': log}\n",
    "        \n",
    "    \n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        x, y = test_batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log('test_loss', loss)\n",
    "        log = {'test_loss': loss}\n",
    "        return {'loss': loss, 'log': log}\n",
    "        \n",
    "        \n",
    "    def validation_epoch_end(self, logits):\n",
    "        val_loss_epoch = torch.stack([x['val_loss'] for x in logits]).mean()\n",
    "        self.log('val_loss_epoch', val_loss_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallbacks(Callback):\n",
    "    \n",
    "    def on_epoch_end(self, trainer, pl_module):\n",
    "        metrics = trainer.callback_metrics\n",
    "        epoch = trainer.current_epoch\n",
    "        print(f\"Epoch {epoch}: {metrics}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Paramteters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'seq_len': 10,\n",
    "     'batch_size': 64,\n",
    "     'num_workers': 8,\n",
    "     'max_epochs': 50,\n",
    "     'learning_rate': 0.001,\n",
    "     'input_size': 17,\n",
    "     'hidden_size': 10,\n",
    "     'num_layers': 1, \n",
    "     'dropout': .2, \n",
    "     'criterion': nn.MSELoss()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frauke/anaconda3/envs/lightning_env/lib/python3.7/site-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/home/frauke/anaconda3/envs/lightning_env/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Experiment logs directory ./lstm/0 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name      | Type    | Params\n",
      "--------------------------------------\n",
      "0 | criterion | MSELoss | 0     \n",
      "1 | lstm      | LSTM    | 1.2 K \n",
      "2 | fc        | Linear  | 11    \n",
      "--------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/6 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frauke/anaconda3/envs/lightning_env/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The {log:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\n",
      "Please use self.log(...) inside the lightningModule instead.\n",
      "\n",
      "# log on a step or aggregate epoch metric to the logger and/or progress bar\n",
      "# (inside LightningModule)\n",
      "self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  33%|███▎      | 2/6 [00:00<00:00, 19.52it/s, loss=2, v_num=0, train_loss=2.3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 6/6 [00:00<00:00, 15.94it/s, loss=2, v_num=0, train_loss=1.71]\n",
      "                                                         \u001b[AEpoch 0: {'loss': tensor(1.7070), 'train_loss': tensor(1.7070), 'val_loss': tensor(2.0318), 'val_loss_epoch': tensor(1.9883)}\n",
      "Epoch 1:  33%|███▎      | 2/6 [00:00<00:00, 17.68it/s, loss=1.87, v_num=0, train_loss=2.07]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 6/6 [00:00<00:00, 22.04it/s, loss=1.87, v_num=0, train_loss=1.41]\n",
      "                                                         \u001b[AEpoch 1: {'loss': tensor(1.4108), 'train_loss': tensor(1.4108), 'val_loss': tensor(1.8664), 'val_loss_epoch': tensor(1.8306)}\n",
      "Epoch 2:  50%|█████     | 3/6 [00:00<00:00, 24.76it/s, loss=1.74, v_num=0, train_loss=1.82]\n",
      "Epoch 2: 100%|██████████| 6/6 [00:00<00:00, 24.46it/s, loss=1.74, v_num=0, train_loss=1.16]\n",
      "                              \u001b[AEpoch 2: {'loss': tensor(1.1617), 'train_loss': tensor(1.1617), 'val_loss': tensor(1.7025), 'val_loss_epoch': tensor(1.6768)}\n",
      "Epoch 3:  50%|█████     | 3/6 [00:00<00:00, 23.59it/s, loss=1.65, v_num=0, train_loss=1.66]\n",
      "Epoch 3: 100%|██████████| 6/6 [00:00<00:00, 26.34it/s, loss=1.65, v_num=0, train_loss=1.66]\n",
      "Epoch 3: 100%|██████████| 6/6 [00:00<00:00, 20.92it/s, loss=1.65, v_num=0, train_loss=1.11]\n",
      "                                                         \u001b[AEpoch 3: {'loss': tensor(1.1064), 'train_loss': tensor(1.1064), 'val_loss': tensor(1.5720), 'val_loss_epoch': tensor(1.5504)}\n",
      "Epoch 4:  50%|█████     | 3/6 [00:00<00:00, 25.38it/s, loss=1.58, v_num=0, train_loss=1.55]\n",
      "Epoch 4: 100%|██████████| 6/6 [00:00<00:00, 25.28it/s, loss=1.58, v_num=0, train_loss=1.06]\n",
      "                              \u001b[AEpoch 4: {'loss': tensor(1.0570), 'train_loss': tensor(1.0570), 'val_loss': tensor(1.4813), 'val_loss_epoch': tensor(1.4625)}\n",
      "Epoch 5:  50%|█████     | 3/6 [00:00<00:00, 25.23it/s, loss=1.53, v_num=0, train_loss=1.48]\n",
      "Epoch 5: 100%|██████████| 6/6 [00:00<00:00, 24.80it/s, loss=1.53, v_num=0, train_loss=1.01]\n",
      "                              \u001b[AEpoch 5: {'loss': tensor(1.0051), 'train_loss': tensor(1.0051), 'val_loss': tensor(1.3971), 'val_loss_epoch': tensor(1.3774)}\n",
      "Epoch 6:  50%|█████     | 3/6 [00:00<00:00, 22.35it/s, loss=1.47, v_num=0, train_loss=1.4] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6: 100%|██████████| 6/6 [00:00<00:00, 20.37it/s, loss=1.47, v_num=0, train_loss=0.931]\n",
      "                                                         \u001b[AEpoch 6: {'loss': tensor(0.9311), 'train_loss': tensor(0.9311), 'val_loss': tensor(1.3087), 'val_loss_epoch': tensor(1.2864)}\n",
      "Epoch 7:  50%|█████     | 3/6 [00:00<00:00, 22.21it/s, loss=1.42, v_num=0, train_loss=1.32] \n",
      "Epoch 7: 100%|██████████| 6/6 [00:00<00:00, 22.97it/s, loss=1.42, v_num=0, train_loss=0.824]\n",
      "                              \u001b[AEpoch 7: {'loss': tensor(0.8237), 'train_loss': tensor(0.8237), 'val_loss': tensor(1.2186), 'val_loss_epoch': tensor(1.1951)}\n",
      "Epoch 8:  50%|█████     | 3/6 [00:00<00:00, 15.92it/s, loss=1.37, v_num=0, train_loss=1.22] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8: 100%|██████████| 6/6 [00:00<00:00, 15.60it/s, loss=1.37, v_num=0, train_loss=0.735]\n",
      "                                                         \u001b[AEpoch 8: {'loss': tensor(0.7349), 'train_loss': tensor(0.7349), 'val_loss': tensor(1.1347), 'val_loss_epoch': tensor(1.1114)}\n",
      "Epoch 9:  50%|█████     | 3/6 [00:00<00:00, 19.97it/s, loss=1.33, v_num=0, train_loss=1.13] \n",
      "Epoch 9: 100%|██████████| 6/6 [00:00<00:00, 20.99it/s, loss=1.33, v_num=0, train_loss=0.688]\n",
      "                              \u001b[AEpoch 9: {'loss': tensor(0.6878), 'train_loss': tensor(0.6878), 'val_loss': tensor(1.0701), 'val_loss_epoch': tensor(1.0475)}\n",
      "Epoch 10:  50%|█████     | 3/6 [00:00<00:00, 18.93it/s, loss=1.21, v_num=0, train_loss=1.06] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10: 100%|██████████| 6/6 [00:00<00:00, 16.19it/s, loss=1.21, v_num=0, train_loss=0.663]\n",
      "                                                         \u001b[AEpoch 10: {'loss': tensor(0.6628), 'train_loss': tensor(0.6628), 'val_loss': tensor(1.0218), 'val_loss_epoch': tensor(1.0004)}\n",
      "Epoch 11:  50%|█████     | 3/6 [00:00<00:00, 17.17it/s, loss=1.12, v_num=0, train_loss=1.02] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11: 100%|██████████| 6/6 [00:00<00:00, 15.95it/s, loss=1.12, v_num=0, train_loss=0.646]\n",
      "                                                         \u001b[AEpoch 11: {'loss': tensor(0.6459), 'train_loss': tensor(0.6459), 'val_loss': tensor(0.9830), 'val_loss_epoch': tensor(0.9630)}\n",
      "Epoch 12:  50%|█████     | 3/6 [00:00<00:00, 20.97it/s, loss=1.05, v_num=0, train_loss=0.977]\n",
      "Epoch 12: 100%|██████████| 6/6 [00:00<00:00, 24.49it/s, loss=1.05, v_num=0, train_loss=0.977]\n",
      "Epoch 12: 100%|██████████| 6/6 [00:00<00:00, 20.02it/s, loss=1.05, v_num=0, train_loss=0.63] \n",
      "                                                         \u001b[AEpoch 12: {'loss': tensor(0.6299), 'train_loss': tensor(0.6299), 'val_loss': tensor(0.9492), 'val_loss_epoch': tensor(0.9304)}\n",
      "Epoch 13:  50%|█████     | 3/6 [00:00<00:00, 20.15it/s, loss=0.994, v_num=0, train_loss=0.943]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13: 100%|██████████| 6/6 [00:00<00:00, 16.44it/s, loss=0.994, v_num=0, train_loss=0.61] \n",
      "                                                         \u001b[AEpoch 13: {'loss': tensor(0.6104), 'train_loss': tensor(0.6104), 'val_loss': tensor(0.9163), 'val_loss_epoch': tensor(0.8984)}\n",
      "Epoch 14:  50%|█████     | 3/6 [00:00<00:00, 18.39it/s, loss=0.938, v_num=0, train_loss=0.912]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14: 100%|██████████| 6/6 [00:00<00:00, 16.04it/s, loss=0.938, v_num=0, train_loss=0.582]\n",
      "                                                         \u001b[AEpoch 14: {'loss': tensor(0.5816), 'train_loss': tensor(0.5816), 'val_loss': tensor(0.8822), 'val_loss_epoch': tensor(0.8647)}\n",
      "Epoch 15:  50%|█████     | 3/6 [00:00<00:00, 21.94it/s, loss=0.886, v_num=0, train_loss=0.882]\n",
      "Epoch 15: 100%|██████████| 6/6 [00:00<00:00, 23.04it/s, loss=0.886, v_num=0, train_loss=0.547]\n",
      "                              \u001b[AEpoch 15: {'loss': tensor(0.5474), 'train_loss': tensor(0.5474), 'val_loss': tensor(0.8475), 'val_loss_epoch': tensor(0.8301)}\n",
      "Epoch 16:  50%|█████     | 3/6 [00:00<00:00, 24.88it/s, loss=0.838, v_num=0, train_loss=0.853]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16: 100%|██████████| 6/6 [00:00<00:00, 20.76it/s, loss=0.838, v_num=0, train_loss=0.522]\n",
      "                                                         \u001b[AEpoch 16: {'loss': tensor(0.5223), 'train_loss': tensor(0.5223), 'val_loss': tensor(0.8157), 'val_loss_epoch': tensor(0.7989)}\n",
      "Epoch 17:  50%|█████     | 3/6 [00:00<00:00, 17.46it/s, loss=0.797, v_num=0, train_loss=0.821]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17: 100%|██████████| 6/6 [00:00<00:00, 17.85it/s, loss=0.797, v_num=0, train_loss=0.496]\n",
      "                                                         \u001b[AEpoch 17: {'loss': tensor(0.4962), 'train_loss': tensor(0.4962), 'val_loss': tensor(0.7839), 'val_loss_epoch': tensor(0.7684)}\n",
      "Epoch 18:  50%|█████     | 3/6 [00:00<00:00, 21.84it/s, loss=0.762, v_num=0, train_loss=0.786]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18: 100%|██████████| 6/6 [00:00<00:00, 19.18it/s, loss=0.762, v_num=0, train_loss=0.47] \n",
      "                                                         \u001b[AEpoch 18: {'loss': tensor(0.4704), 'train_loss': tensor(0.4704), 'val_loss': tensor(0.7452), 'val_loss_epoch': tensor(0.7308)}\n",
      "Epoch 19:  50%|█████     | 3/6 [00:00<00:00, 18.40it/s, loss=0.731, v_num=0, train_loss=0.747]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19: 100%|██████████| 6/6 [00:00<00:00, 16.70it/s, loss=0.731, v_num=0, train_loss=0.446]\n",
      "                                                         \u001b[AEpoch 19: {'loss': tensor(0.4460), 'train_loss': tensor(0.4460), 'val_loss': tensor(0.6973), 'val_loss_epoch': tensor(0.6830)}\n",
      "Epoch 20:  50%|█████     | 3/6 [00:00<00:00, 21.05it/s, loss=0.699, v_num=0, train_loss=0.699]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20: 100%|██████████| 6/6 [00:00<00:00, 18.42it/s, loss=0.699, v_num=0, train_loss=0.402]\n",
      "                                                         \u001b[AEpoch 20: {'loss': tensor(0.4021), 'train_loss': tensor(0.4021), 'val_loss': tensor(0.6470), 'val_loss_epoch': tensor(0.6316)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  50%|█████     | 3/6 [00:00<00:00, 18.41it/s, loss=0.667, v_num=0, train_loss=0.649]\n",
      "Epoch 21: 100%|██████████| 6/6 [00:00<00:00, 20.22it/s, loss=0.667, v_num=0, train_loss=0.364]\n",
      "                              \u001b[AEpoch 21: {'loss': tensor(0.3642), 'train_loss': tensor(0.3642), 'val_loss': tensor(0.6073), 'val_loss_epoch': tensor(0.5913)}\n",
      "Epoch 22:  50%|█████     | 3/6 [00:00<00:00, 22.88it/s, loss=0.635, v_num=0, train_loss=0.616]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22: 100%|██████████| 6/6 [00:00<00:00, 18.90it/s, loss=0.635, v_num=0, train_loss=0.347]\n",
      "                                                         \u001b[AEpoch 22: {'loss': tensor(0.3469), 'train_loss': tensor(0.3469), 'val_loss': tensor(0.5831), 'val_loss_epoch': tensor(0.5673)}\n",
      "Epoch 23:  50%|█████     | 3/6 [00:00<00:00, 20.74it/s, loss=0.603, v_num=0, train_loss=0.596]\n",
      "Epoch 23: 100%|██████████| 6/6 [00:00<00:00, 22.35it/s, loss=0.603, v_num=0, train_loss=0.332]\n",
      "                              \u001b[AEpoch 23: {'loss': tensor(0.3321), 'train_loss': tensor(0.3321), 'val_loss': tensor(0.5691), 'val_loss_epoch': tensor(0.5534)}\n",
      "Epoch 24:  50%|█████     | 3/6 [00:00<00:00, 22.88it/s, loss=0.574, v_num=0, train_loss=0.58] \n",
      "Epoch 24: 100%|██████████| 6/6 [00:00<00:00, 23.03it/s, loss=0.574, v_num=0, train_loss=0.316]\n",
      "                              \u001b[AEpoch 24: {'loss': tensor(0.3162), 'train_loss': tensor(0.3162), 'val_loss': tensor(0.5597), 'val_loss_epoch': tensor(0.5441)}\n",
      "Epoch 25:  50%|█████     | 3/6 [00:00<00:00, 23.80it/s, loss=0.546, v_num=0, train_loss=0.568]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 25: 100%|██████████| 6/6 [00:00<00:00, 19.64it/s, loss=0.546, v_num=0, train_loss=0.304]\n",
      "                                                         \u001b[AEpoch 25: {'loss': tensor(0.3037), 'train_loss': tensor(0.3037), 'val_loss': tensor(0.5522), 'val_loss_epoch': tensor(0.5368)}\n",
      "Epoch 26:  50%|█████     | 3/6 [00:00<00:00, 17.13it/s, loss=0.52, v_num=0, train_loss=0.558] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 26: 100%|██████████| 6/6 [00:00<00:00, 17.25it/s, loss=0.52, v_num=0, train_loss=0.297]\n",
      "                                                         \u001b[AEpoch 26: {'loss': tensor(0.2966), 'train_loss': tensor(0.2966), 'val_loss': tensor(0.5457), 'val_loss_epoch': tensor(0.5302)}\n",
      "Epoch 27:  50%|█████     | 3/6 [00:00<00:00, 17.46it/s, loss=0.496, v_num=0, train_loss=0.55] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 27: 100%|██████████| 6/6 [00:00<00:00, 16.93it/s, loss=0.496, v_num=0, train_loss=0.292]\n",
      "                                                         \u001b[AEpoch 27: {'loss': tensor(0.2917), 'train_loss': tensor(0.2917), 'val_loss': tensor(0.5395), 'val_loss_epoch': tensor(0.5239)}\n",
      "Epoch 28:  50%|█████     | 3/6 [00:00<00:00, 20.79it/s, loss=0.475, v_num=0, train_loss=0.543]\n",
      "Epoch 28: 100%|██████████| 6/6 [00:00<00:00, 20.71it/s, loss=0.475, v_num=0, train_loss=0.288]\n",
      "                              \u001b[AEpoch 28: {'loss': tensor(0.2876), 'train_loss': tensor(0.2876), 'val_loss': tensor(0.5336), 'val_loss_epoch': tensor(0.5180)}\n",
      "Epoch 29:  50%|█████     | 3/6 [00:00<00:00, 22.24it/s, loss=0.456, v_num=0, train_loss=0.536]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 29: 100%|██████████| 6/6 [00:00<00:00, 18.46it/s, loss=0.456, v_num=0, train_loss=0.284]\n",
      "                                                         \u001b[AEpoch 29: {'loss': tensor(0.2837), 'train_loss': tensor(0.2837), 'val_loss': tensor(0.5280), 'val_loss_epoch': tensor(0.5124)}\n",
      "Epoch 30:  50%|█████     | 3/6 [00:00<00:00, 17.08it/s, loss=0.441, v_num=0, train_loss=0.531]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 30: 100%|██████████| 6/6 [00:00<00:00, 16.73it/s, loss=0.441, v_num=0, train_loss=0.28] \n",
      "                                                         \u001b[AEpoch 30: {'loss': tensor(0.2801), 'train_loss': tensor(0.2801), 'val_loss': tensor(0.5227), 'val_loss_epoch': tensor(0.5069)}\n",
      "Epoch 31:  50%|█████     | 3/6 [00:00<00:00, 20.93it/s, loss=0.431, v_num=0, train_loss=0.525]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 31: 100%|██████████| 6/6 [00:00<00:00, 18.33it/s, loss=0.431, v_num=0, train_loss=0.277]\n",
      "                                                         \u001b[AEpoch 31: {'loss': tensor(0.2765), 'train_loss': tensor(0.2765), 'val_loss': tensor(0.5174), 'val_loss_epoch': tensor(0.5017)}\n",
      "Epoch 32:  50%|█████     | 3/6 [00:00<00:00, 21.29it/s, loss=0.422, v_num=0, train_loss=0.52] \n",
      "Epoch 32: 100%|██████████| 6/6 [00:00<00:00, 23.35it/s, loss=0.422, v_num=0, train_loss=0.273]\n",
      "                              \u001b[AEpoch 32: {'loss': tensor(0.2731), 'train_loss': tensor(0.2731), 'val_loss': tensor(0.5124), 'val_loss_epoch': tensor(0.4966)}\n",
      "Epoch 33:  50%|█████     | 3/6 [00:00<00:00, 21.25it/s, loss=0.415, v_num=0, train_loss=0.515]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 33: 100%|██████████| 6/6 [00:00<00:00, 19.11it/s, loss=0.415, v_num=0, train_loss=0.27] \n",
      "                                                         \u001b[AEpoch 33: {'loss': tensor(0.2698), 'train_loss': tensor(0.2698), 'val_loss': tensor(0.5075), 'val_loss_epoch': tensor(0.4917)}\n",
      "Epoch 34:  50%|█████     | 3/6 [00:00<00:00, 23.20it/s, loss=0.409, v_num=0, train_loss=0.51]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 34: 100%|██████████| 6/6 [00:00<00:00, 18.98it/s, loss=0.409, v_num=0, train_loss=0.267]\n",
      "                                                         \u001b[AEpoch 34: {'loss': tensor(0.2665), 'train_loss': tensor(0.2665), 'val_loss': tensor(0.5027), 'val_loss_epoch': tensor(0.4869)}\n",
      "Epoch 35:  50%|█████     | 3/6 [00:00<00:00, 16.15it/s, loss=0.404, v_num=0, train_loss=0.505]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 35: 100%|██████████| 6/6 [00:00<00:00, 15.29it/s, loss=0.404, v_num=0, train_loss=0.263]\n",
      "                                                         \u001b[AEpoch 35: {'loss': tensor(0.2634), 'train_loss': tensor(0.2634), 'val_loss': tensor(0.4980), 'val_loss_epoch': tensor(0.4822)}\n",
      "Epoch 36:  50%|█████     | 3/6 [00:00<00:00, 15.75it/s, loss=0.399, v_num=0, train_loss=0.5]  \n",
      "Epoch 36: 100%|██████████| 6/6 [00:00<00:00, 20.47it/s, loss=0.399, v_num=0, train_loss=0.5]\n",
      "Epoch 36: 100%|██████████| 6/6 [00:00<00:00, 17.78it/s, loss=0.399, v_num=0, train_loss=0.26]\n",
      "                                                         \u001b[AEpoch 36: {'loss': tensor(0.2603), 'train_loss': tensor(0.2603), 'val_loss': tensor(0.4935), 'val_loss_epoch': tensor(0.4777)}\n",
      "Epoch 37:  50%|█████     | 3/6 [00:00<00:00, 23.17it/s, loss=0.395, v_num=0, train_loss=0.495]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 37: 100%|██████████| 6/6 [00:00<00:00, 19.77it/s, loss=0.395, v_num=0, train_loss=0.257]\n",
      "                                                         \u001b[AEpoch 37: {'loss': tensor(0.2574), 'train_loss': tensor(0.2574), 'val_loss': tensor(0.4890), 'val_loss_epoch': tensor(0.4732)}\n",
      "Epoch 38:  50%|█████     | 3/6 [00:00<00:00, 21.50it/s, loss=0.391, v_num=0, train_loss=0.491]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 38: 100%|██████████| 6/6 [00:00<00:00, 19.32it/s, loss=0.391, v_num=0, train_loss=0.254]\n",
      "                                                         \u001b[AEpoch 38: {'loss': tensor(0.2544), 'train_loss': tensor(0.2544), 'val_loss': tensor(0.4846), 'val_loss_epoch': tensor(0.4688)}\n",
      "Epoch 39:  50%|█████     | 3/6 [00:00<00:00, 22.80it/s, loss=0.386, v_num=0, train_loss=0.486]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 39: 100%|██████████| 6/6 [00:00<00:00, 19.12it/s, loss=0.386, v_num=0, train_loss=0.252]\n",
      "                                                         \u001b[AEpoch 39: {'loss': tensor(0.2516), 'train_loss': tensor(0.2516), 'val_loss': tensor(0.4803), 'val_loss_epoch': tensor(0.4645)}\n",
      "Epoch 40:  50%|█████     | 3/6 [00:00<00:00, 20.53it/s, loss=0.382, v_num=0, train_loss=0.482]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 40: 100%|██████████| 6/6 [00:00<00:00, 17.31it/s, loss=0.382, v_num=0, train_loss=0.249]\n",
      "                                                         \u001b[AEpoch 40: {'loss': tensor(0.2489), 'train_loss': tensor(0.2489), 'val_loss': tensor(0.4762), 'val_loss_epoch': tensor(0.4603)}\n",
      "Epoch 41:  50%|█████     | 3/6 [00:00<00:00, 21.96it/s, loss=0.379, v_num=0, train_loss=0.477]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 6/6 [00:00<00:00, 18.19it/s, loss=0.379, v_num=0, train_loss=0.246]\n",
      "                                                         \u001b[AEpoch 41: {'loss': tensor(0.2462), 'train_loss': tensor(0.2462), 'val_loss': tensor(0.4720), 'val_loss_epoch': tensor(0.4562)}\n",
      "Epoch 42:  50%|█████     | 3/6 [00:00<00:00, 22.06it/s, loss=0.375, v_num=0, train_loss=0.473]\n",
      "Epoch 42: 100%|██████████| 6/6 [00:00<00:00, 24.23it/s, loss=0.375, v_num=0, train_loss=0.244]\n",
      "                              \u001b[AEpoch 42: {'loss': tensor(0.2436), 'train_loss': tensor(0.2436), 'val_loss': tensor(0.4680), 'val_loss_epoch': tensor(0.4522)}\n",
      "Epoch 43:  50%|█████     | 3/6 [00:00<00:00, 17.74it/s, loss=0.371, v_num=0, train_loss=0.469]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 43: 100%|██████████| 6/6 [00:00<00:00, 17.81it/s, loss=0.371, v_num=0, train_loss=0.241]\n",
      "                                                         \u001b[AEpoch 43: {'loss': tensor(0.2410), 'train_loss': tensor(0.2410), 'val_loss': tensor(0.4641), 'val_loss_epoch': tensor(0.4483)}\n",
      "Epoch 44:  50%|█████     | 3/6 [00:00<00:00, 23.62it/s, loss=0.367, v_num=0, train_loss=0.465]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 44: 100%|██████████| 6/6 [00:00<00:00, 19.43it/s, loss=0.367, v_num=0, train_loss=0.239]\n",
      "                                                         \u001b[AEpoch 44: {'loss': tensor(0.2385), 'train_loss': tensor(0.2385), 'val_loss': tensor(0.4602), 'val_loss_epoch': tensor(0.4444)}\n",
      "Epoch 45:  50%|█████     | 3/6 [00:00<00:00, 23.14it/s, loss=0.364, v_num=0, train_loss=0.461]\n",
      "Epoch 45: 100%|██████████| 6/6 [00:00<00:00, 22.48it/s, loss=0.364, v_num=0, train_loss=0.236]\n",
      "                              \u001b[AEpoch 45: {'loss': tensor(0.2361), 'train_loss': tensor(0.2361), 'val_loss': tensor(0.4564), 'val_loss_epoch': tensor(0.4406)}\n",
      "Epoch 46:  50%|█████     | 3/6 [00:00<00:00, 21.93it/s, loss=0.36, v_num=0, train_loss=0.457] \n",
      "Epoch 46: 100%|██████████| 6/6 [00:00<00:00, 20.88it/s, loss=0.36, v_num=0, train_loss=0.234]\n",
      "                              \u001b[AEpoch 46: {'loss': tensor(0.2338), 'train_loss': tensor(0.2338), 'val_loss': tensor(0.4527), 'val_loss_epoch': tensor(0.4369)}\n",
      "Epoch 47:  50%|█████     | 3/6 [00:00<00:00, 23.23it/s, loss=0.357, v_num=0, train_loss=0.453]\n",
      "Epoch 47: 100%|██████████| 6/6 [00:00<00:00, 22.00it/s, loss=0.357, v_num=0, train_loss=0.231]\n",
      "                              \u001b[AEpoch 47: {'loss': tensor(0.2315), 'train_loss': tensor(0.2315), 'val_loss': tensor(0.4491), 'val_loss_epoch': tensor(0.4333)}\n",
      "Epoch 48:  50%|█████     | 3/6 [00:00<00:00, 19.14it/s, loss=0.354, v_num=0, train_loss=0.45] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 48: 100%|██████████| 6/6 [00:00<00:00, 18.62it/s, loss=0.354, v_num=0, train_loss=0.229]\n",
      "                                                         \u001b[AEpoch 48: {'loss': tensor(0.2293), 'train_loss': tensor(0.2293), 'val_loss': tensor(0.4456), 'val_loss_epoch': tensor(0.4297)}\n",
      "Epoch 49:  50%|█████     | 3/6 [00:00<00:00, 24.89it/s, loss=0.35, v_num=0, train_loss=0.446] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 49: 100%|██████████| 6/6 [00:00<00:00, 21.25it/s, loss=0.35, v_num=0, train_loss=0.227]\n",
      "                                                         \u001b[AEpoch 49: {'loss': tensor(0.2271), 'train_loss': tensor(0.2271), 'val_loss': tensor(0.4421), 'val_loss_epoch': tensor(0.4262)}\n",
      "Epoch 49: 100%|██████████| 6/6 [00:00<00:00, 19.83it/s, loss=0.35, v_num=0, train_loss=0.227]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_logger = CSVLogger('./', name='lstm', version='0'),\n",
    "\n",
    "data_module = PowUsageDataModule(seq_len=p['seq_len'], batch_size=p['batch_size'], \n",
    "                                 num_workers=p['num_workers'])\n",
    "\n",
    "model = PowUsageModel(input_size=p['input_size'], learning_rate=p['learning_rate'], \n",
    "                      hidden_size=p['hidden_size'], num_layers=p['num_layers'], dropout=p['dropout'], \n",
    "                      criterion=p['criterion'])\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor='val_loss_epoch',\n",
    "                                        min_delta=0.00,\n",
    "                                        patience=10,\n",
    "                                        verbose=False,\n",
    "                                        mode='min')\n",
    "\n",
    "trainer = pl.Trainer(callbacks=[early_stop_callback, CustomCallbacks()], max_epochs=p['max_epochs'], logger=csv_logger)\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_loss_epoch</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.031821</td>\n",
       "      <td>1.988346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.866373</td>\n",
       "      <td>1.830570</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.702493</td>\n",
       "      <td>1.676819</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.572041</td>\n",
       "      <td>1.550434</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.481326</td>\n",
       "      <td>1.462491</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   val_loss  val_loss_epoch  epoch  step  train_loss\n",
       "0  2.031821        1.988346    0.0     1         NaN\n",
       "1  1.866373        1.830570    1.0     3         NaN\n",
       "2  1.702493        1.676819    2.0     5         NaN\n",
       "3  1.572041        1.550434    3.0     7         NaN\n",
       "4  1.481326        1.462491    4.0     9         NaN"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = pd.read_csv('./lstm/0/metrics.csv')\n",
    "metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:\n",
      "Val loss:   0.426\n"
     ]
    }
   ],
   "source": [
    "val_loss = metrics[['val_loss_epoch', 'epoch']]\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(8, 5), dpi=100)\n",
    "#axes[0].set_title('Train loss per batch')\n",
    "#axes[0].plot(train_loss['step'], train_loss['train_loss'])\n",
    "axes.set_title('Validation loss per epoch')\n",
    "axes.plot(val_loss['epoch'], val_loss['val_loss_epoch'], color='orange')\n",
    "plt.show(block = True)\n",
    "\n",
    "print('MSE:')\n",
    "#print(f\"Train loss: {train_loss['train_loss'].iloc[-1]:.3f}\")\n",
    "print(f\"Val loss:   {val_loss['val_loss_epoch'].iloc[-1]:.3f}\")\n",
    "#print(f'Test loss:  {test_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
